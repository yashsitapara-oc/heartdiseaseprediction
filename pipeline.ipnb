import kfp
import os

# Load DKube components
components_url = "/mnt/dkube/pipeline/components/"
dkube_training_op = kfp.components.load_component_from_file(components_url + "training/component.yaml")
dkube_serving_op = kfp.components.load_component_from_file(components_url + "serving/component.yaml")

token = os.getenv("DKUBE_USER_ACCESS_TOKEN")
client = kfp.Client(host=os.getenv("KF_PIPELINES_ENDPOINT"), existing_token=token)

@kfp.dsl.pipeline(name='heart-disease-pipeline')
def heart_pipeline():
    # 1. Training Step
    train = dkube_training_op(
        auth_token=token,
        container='{"image":"ocdr/d3-datascience-sklearn:v0.23.2-1"}',
        framework="sklearn", version="0.23.2",
        program="heart-project", run_script="python train.py",
        datasets='["heart-data"]', 
        outputs='["heart-model"]'
    )

    # 2. Serving Step (depends on training)
    serving = dkube_serving_op(
        auth_token=token,
        model=train.outputs['artifact'],
        device='cpu',
        transformer_code='transformer.py'
    ).after(train)

client.create_run_from_pipeline_func(heart_pipeline, arguments={})